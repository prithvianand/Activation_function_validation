# Activation_function_validation

# Activation Function
    - Sigmoid
    - Tanh
    - Rectified Linear Unit (ReLU)
#### Sigmoid Function
    - A = 1/(1 + e-x)
    - Value Range : 0 to 1
![sigmoid](https://user-images.githubusercontent.com/43229037/116681624-d790a180-a9ca-11eb-9731-17e9e0c599bb.png)
#### Tanh Function
    - f(x) = tanh(x) = 2/(1 + e-2x) - 1
    - tanh(x) = 2 * sigmoid(2x) - 1
![tanh1](https://user-images.githubusercontent.com/43229037/116681650-df504600-a9ca-11eb-9320-316199484a5d.png)
#### RELU
    - A(x) = max(0,x)
![relu](https://user-images.githubusercontent.com/43229037/116681602-cf386680-a9ca-11eb-879e-87e04dd035c5.png)

# This is the observation made
![download](https://user-images.githubusercontent.com/43229037/116681810-132b6b80-a9cb-11eb-8dc7-893d83753d07.png)
### above observation shows that sigmoid function work well for the given data set
